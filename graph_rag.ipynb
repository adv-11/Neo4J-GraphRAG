{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<md>References:\n",
        "\n",
        "https://neo4j.com/developer-blog/knowledge-graph-rag-application/\n",
        "\n",
        "\n",
        "https://towardsdatascience.com/how-to-implement-graph-rag-using-knowledge-graphs-and-vector-databases-60bb69a22759\n",
        "\n",
        "https://neo4j.com/blog/graphrag-manifesto/\n",
        "\n",
        "https://spg.openkg.cn/en-US\n",
        "\n",
        "https://github.com/OpenSPG/KAG\n",
        "\n",
        "https://openspg.yuque.com/ndx6g9/cwh47i/rs7gr8g4s538b1n7#cikso\n",
        "\n",
        "https://arxiv.org/abs/2409.13731\n",
        "\n",
        "https://medium.com/@zilliz_learn/graphrag-explained-enhancing-rag-with-knowledge-graphs-3312065f99e1\n",
        "\n",
        "\n",
        "\n",
        "</md>"
      ],
      "metadata": {
        "collapsed": false,
        "id": "aNhXJZQ7WE-Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##GraphRAG with NEO 4J"
      ],
      "metadata": {
        "id": "fyUVCmk5eFsg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prereq"
      ],
      "metadata": {
        "id": "G0r8YnuyFWkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-community neo4j python-dotenv -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5M8rgxdIeh78",
        "outputId": "b17009ca-013d-4ab8-9130-e83c5528a904"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.14)\n",
            "Collecting langchain-community\n",
            "  Using cached langchain_community-0.3.14-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: neo4j in /usr/local/lib/python3.10/dist-packages (5.27.0)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.11)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.29)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.4)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.10)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from neo4j) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.24.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.13)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.2.2)\n",
            "Downloading langchain_community-0.3.14-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading marshmallow-3.24.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.14 marshmallow-3.24.2 mypy-extensions-1.0.0 pydantic-settings-2.7.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-neo4j -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcqjB0JGhCQ9",
        "outputId": "a712f51f-50fa-479c-c97b-6e24a95ac3d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/301.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m297.0/301.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.7/301.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "\n",
        "# Warning control\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "Q-VALWir6cyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv('.env', override=True)\n",
        "NEO4J_URI = os.getenv('NEO4J_URI')\n",
        "NEO4J_USERNAME = os.getenv('NEO4J_USERNAME')\n",
        "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
        "NEO4J_DATABASE = os.getenv('NEO4J_DATABASE')"
      ],
      "metadata": {
        "id": "rWA-sAgm7N5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize a Knowledge graph intance using LangCHain\n"
      ],
      "metadata": {
        "id": "ySrxcIf77c4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kg = Neo4jGraph(\n",
        "    url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD, database=NEO4J_DATABASE\n",
        ")\n",
        "kg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbOQQQZ-7kkf",
        "outputId": "09060679-887d-4812-faea-04271ae59a74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_community.graphs.neo4j_graph.Neo4jGraph at 0x7a00e7f9c400>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cypher = \"\"\"\n",
        "CREATE (andreas:Person {name:\"Advait\"})\n",
        "RETURN andreas\n",
        "\"\"\"\n",
        "\n",
        "kg.query(cypher)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12I2wqgO7VLT",
        "outputId": "8c454601-65eb-4028-cfcd-11f9d375ec7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'andreas': {'name': 'Advait'}}]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cypher = \"\"\"\n",
        "  MATCH (n)\n",
        "  RETURN count(n)\n",
        "  \"\"\"\n",
        "\n",
        "kg.query(cypher)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2WOjMnb8A8A",
        "outputId": "87d07ca4-02f7-4fec-8cb6-0a2dfbc9e120"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'count(n)': 2}]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### RAG"
      ],
      "metadata": {
        "id": "efp095Br9jm-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "onN0UlTn9rf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph RAG with Milvus"
      ],
      "metadata": {
        "id": "Zq_U2rBgd1rb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "iZu2XsK-WE-b"
      },
      "outputs": [],
      "source": [
        "! pip install --upgrade --quiet pymilvus numpy scipy langchain langchain-core langchain-mistralai tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Gc4xyvVPWE-d"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "MISTRAL_API_KEY = userdata.get('MISTRAL_API_KEY')\n",
        "\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the necessary libraries and dependencies."
      ],
      "metadata": {
        "collapsed": false,
        "id": "aEHMzXvfWE-e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2NuCxQHWE-e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from collections import defaultdict\n",
        "from scipy.sparse import csr_matrix\n",
        "from pymilvus import MilvusClient\n",
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
        "from langchain_mistralai import ChatMistralAI, MistralAIEmbeddings\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize the instance of Milvus client, the LLM, and the embedding model."
      ],
      "metadata": {
        "collapsed": false,
        "id": "_tYXV7zUWE-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"MISTRAL_API_KEY\"] = MISTRAL_API_KEY\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HF_TOKEN"
      ],
      "metadata": {
        "id": "ItqYlaLaYORL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "q7Fp0JgwWE-f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dba6face-441a-4651-b71b-329eb90479f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_mistralai/embeddings.py:180: UserWarning: Could not download mistral tokenizer from Huggingface for calculating batch sizes. Set a Huggingface token via the HF_TOKEN environment variable to download the real tokenizer. Falling back to a dummy tokenizer that uses `len()`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "milvus_client = MilvusClient(uri=\"./milvus.db\")\n",
        "\n",
        "llm = ChatMistralAI(\n",
        "    model=\"open-mistral-7b\",\n",
        "    temperature=0,\n",
        ")\n",
        "embedding_model =  MistralAIEmbeddings(\n",
        "    model=\"mistral-embed\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Offline Data Loading\n",
        "### Data Preparation\n",
        "\n",
        "We will use a nano dataset which introduce the relationship between Bernoulli family and Euler to demonstrate as an example. The nano dataset contains 4 passages and a set of corresponding triplets, where each triplet contains a subject, a predicate, and an object.\n",
        "In practice, you can use any approach to extract the triplets from your own custom corpus."
      ],
      "metadata": {
        "collapsed": false,
        "id": "j3UhBeRwWE-g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "NFbQDfwGWE-g"
      },
      "outputs": [],
      "source": [
        "nano_dataset = [\n",
        "    {\n",
        "        \"passage\": \"Jakob Bernoulli (1654–1705): Jakob was one of the earliest members of the Bernoulli family to gain prominence in mathematics. He made significant contributions to calculus, particularly in the development of the theory of probability. He is known for the Bernoulli numbers and the Bernoulli theorem, a precursor to the law of large numbers. He was the older brother of Johann Bernoulli, another influential mathematician, and the two had a complex relationship that involved both collaboration and rivalry.\",\n",
        "        \"triplets\": [\n",
        "            [\"Jakob Bernoulli\", \"made significant contributions to\", \"calculus\"],\n",
        "            [\n",
        "                \"Jakob Bernoulli\",\n",
        "                \"made significant contributions to\",\n",
        "                \"the theory of probability\",\n",
        "            ],\n",
        "            [\"Jakob Bernoulli\", \"is known for\", \"the Bernoulli numbers\"],\n",
        "            [\"Jakob Bernoulli\", \"is known for\", \"the Bernoulli theorem\"],\n",
        "            [\"The Bernoulli theorem\", \"is a precursor to\", \"the law of large numbers\"],\n",
        "            [\"Jakob Bernoulli\", \"was the older brother of\", \"Johann Bernoulli\"],\n",
        "        ],\n",
        "    },\n",
        "    {\n",
        "        \"passage\": \"Johann Bernoulli (1667–1748): Johann, Jakob’s younger brother, was also a major figure in the development of calculus. He worked on infinitesimal calculus and was instrumental in spreading the ideas of Leibniz across Europe. Johann also contributed to the calculus of variations and was known for his work on the brachistochrone problem, which is the curve of fastest descent between two points.\",\n",
        "        \"triplets\": [\n",
        "            [\n",
        "                \"Johann Bernoulli\",\n",
        "                \"was a major figure of\",\n",
        "                \"the development of calculus\",\n",
        "            ],\n",
        "            [\"Johann Bernoulli\", \"was\", \"Jakob's younger brother\"],\n",
        "            [\"Johann Bernoulli\", \"worked on\", \"infinitesimal calculus\"],\n",
        "            [\"Johann Bernoulli\", \"was instrumental in spreading\", \"Leibniz's ideas\"],\n",
        "            [\"Johann Bernoulli\", \"contributed to\", \"the calculus of variations\"],\n",
        "            [\"Johann Bernoulli\", \"was known for\", \"the brachistochrone problem\"],\n",
        "        ],\n",
        "    },\n",
        "    {\n",
        "        \"passage\": \"Daniel Bernoulli (1700–1782): The son of Johann Bernoulli, Daniel made major contributions to fluid dynamics, probability, and statistics. He is most famous for Bernoulli’s principle, which describes the behavior of fluid flow and is fundamental to the understanding of aerodynamics.\",\n",
        "        \"triplets\": [\n",
        "            [\"Daniel Bernoulli\", \"was the son of\", \"Johann Bernoulli\"],\n",
        "            [\"Daniel Bernoulli\", \"made major contributions to\", \"fluid dynamics\"],\n",
        "            [\"Daniel Bernoulli\", \"made major contributions to\", \"probability\"],\n",
        "            [\"Daniel Bernoulli\", \"made major contributions to\", \"statistics\"],\n",
        "            [\"Daniel Bernoulli\", \"is most famous for\", \"Bernoulli’s principle\"],\n",
        "            [\n",
        "                \"Bernoulli’s principle\",\n",
        "                \"is fundamental to\",\n",
        "                \"the understanding of aerodynamics\",\n",
        "            ],\n",
        "        ],\n",
        "    },\n",
        "    {\n",
        "        \"passage\": \"Leonhard Euler (1707–1783) was one of the greatest mathematicians of all time, and his relationship with the Bernoulli family was significant. Euler was born in Basel and was a student of Johann Bernoulli, who recognized his exceptional talent and mentored him in mathematics. Johann Bernoulli’s influence on Euler was profound, and Euler later expanded upon many of the ideas and methods he learned from the Bernoullis.\",\n",
        "        \"triplets\": [\n",
        "            [\n",
        "                \"Leonhard Euler\",\n",
        "                \"had a significant relationship with\",\n",
        "                \"the Bernoulli family\",\n",
        "            ],\n",
        "            [\"leonhard Euler\", \"was born in\", \"Basel\"],\n",
        "            [\"Leonhard Euler\", \"was a student of\", \"Johann Bernoulli\"],\n",
        "            [\"Johann Bernoulli's influence\", \"was profound on\", \"Euler\"],\n",
        "        ],\n",
        "    },\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "another known dataset"
      ],
      "metadata": {
        "id": "hJfH28_4Z1u2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "known_scientists_dataset = [\n",
        "    {\n",
        "        \"passage\": \"Albert Einstein (1879–1955): Einstein was a theoretical physicist who developed the theory of relativity, one of the two pillars of modern physics. His equation E=mc², which expresses the equivalence of mass and energy, is one of the most famous equations in the world. Einstein's work revolutionized our understanding of space, time, and gravity.\",\n",
        "        \"triplets\": [\n",
        "            [\"Albert Einstein\", \"developed\", \"the theory of relativity\"],\n",
        "            [\"Albert Einstein\", \"is known for\", \"the equation E=mc²\"],\n",
        "            [\"E=mc²\", \"expresses\", \"the equivalence of mass and energy\"],\n",
        "            [\"Einstein's work\", \"revolutionized\", \"understanding of space, time, and gravity\"],\n",
        "        ],\n",
        "    },\n",
        "    {\n",
        "        \"passage\": \"Isaac Newton (1643–1727): Newton was an English mathematician, physicist, astronomer, and author who is widely recognized as one of the most influential scientists of all time. He formulated the laws of motion and universal gravitation, laying the groundwork for classical mechanics.\",\n",
        "        \"triplets\": [\n",
        "            [\"Isaac Newton\", \"formulated\", \"the laws of motion\"],\n",
        "            [\"Isaac Newton\", \"formulated\", \"universal gravitation\"],\n",
        "            [\"Newton's laws\", \"laid the groundwork for\", \"classical mechanics\"],\n",
        "            [\"Isaac Newton\", \"is recognized as\", \"one of the most influential scientists\"],\n",
        "        ],\n",
        "    },\n",
        "    {\n",
        "        \"passage\": \"Niels Bohr (1885–1962): Bohr was a Danish physicist who made foundational contributions to understanding atomic structure and quantum theory. He proposed the Bohr model of the atom, which describes electrons orbiting the nucleus at fixed distances.\",\n",
        "        \"triplets\": [\n",
        "            [\"Niels Bohr\", \"made contributions to\", \"atomic structure\"],\n",
        "            [\"Niels Bohr\", \"made contributions to\", \"quantum theory\"],\n",
        "            [\"Niels Bohr\", \"proposed\", \"the Bohr model of the atom\"],\n",
        "            [\"The Bohr model\", \"describes\", \"electrons orbiting the nucleus\"],\n",
        "        ],\n",
        "    },\n",
        "    {\n",
        "        \"passage\": \"Galileo Galilei (1564–1642): Galileo was an Italian astronomer, physicist, and engineer who is often referred to as the father of modern observational astronomy. He made significant improvements to the telescope and is known for his discoveries of the moons of Jupiter and the phases of Venus.\",\n",
        "        \"triplets\": [\n",
        "            [\"Galileo Galilei\", \"is referred to as\", \"the father of modern observational astronomy\"],\n",
        "            [\"Galileo Galilei\", \"made improvements to\", \"the telescope\"],\n",
        "            [\"Galileo Galilei\", \"is known for\", \"discoveries of the moons of Jupiter\"],\n",
        "            [\"Galileo Galilei\", \"is known for\", \"discoveries of the phases of Venus\"],\n",
        "        ],\n",
        "    },\n",
        "    {\n",
        "        \"passage\": \"Marie Curie (1867–1934): Curie was a Polish-born physicist and chemist who conducted pioneering research on radioactivity. She was the first woman to win a Nobel Prize and remains the only person to win Nobel Prizes in two different scientific fields: Physics and Chemistry.\",\n",
        "        \"triplets\": [\n",
        "            [\"Marie Curie\", \"conducted research on\", \"radioactivity\"],\n",
        "            [\"Marie Curie\", \"was the first woman to win\", \"a Nobel Prize\"],\n",
        "            [\"Marie Curie\", \"is the only person to win\", \"Nobel Prizes in two fields\"],\n",
        "            [\"Marie Curie\", \"won Nobel Prizes in\", \"Physics and Chemistry\"],\n",
        "        ],\n",
        "    },\n",
        "]"
      ],
      "metadata": {
        "id": "ntxdH7RfZ4dn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We construct the entities and relations as follows:\n",
        "- The entity is the subject or object in the triplet, so we directly extract them from the triplets.\n",
        "- Here we construct the concept of relationship by directly concatenating the subject, predicate, and object with a space in between.\n",
        "\n",
        "We also prepare a dict to map entity id to relation id, and another dict to map relation id to passage id for later use.\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "Ahb0cX2qWE-h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "rSXV1AqHWE-h"
      },
      "outputs": [],
      "source": [
        "entityid_2_relationids = defaultdict(list)\n",
        "relationid_2_passageids = defaultdict(list)\n",
        "\n",
        "entities = []\n",
        "relations = []\n",
        "passages = []\n",
        "for passage_id, dataset_info in enumerate(nano_dataset):\n",
        "    passage, triplets = dataset_info[\"passage\"], dataset_info[\"triplets\"]\n",
        "    passages.append(passage)\n",
        "    for triplet in triplets:\n",
        "        if triplet[0] not in entities:\n",
        "            entities.append(triplet[0])\n",
        "        if triplet[2] not in entities:\n",
        "            entities.append(triplet[2])\n",
        "        relation = \" \".join(triplet)\n",
        "        if relation not in relations:\n",
        "            relations.append(relation)\n",
        "            entityid_2_relationids[entities.index(triplet[0])].append(\n",
        "                len(relations) - 1\n",
        "            )\n",
        "            entityid_2_relationids[entities.index(triplet[2])].append(\n",
        "                len(relations) - 1\n",
        "            )\n",
        "        relationid_2_passageids[relations.index(relation)].append(passage_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Insertion\n",
        "\n",
        "Create Milvus collections for entity, relation, and passage. The entity collection and relation collection are used as the major collections for graph construction in our method, while the passage collection is used as the naive RAG retrieval comparison or auxiliary purpose."
      ],
      "metadata": {
        "collapsed": false,
        "id": "xZ-hVn99WE-h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "rYEXg621WE-h"
      },
      "outputs": [],
      "source": [
        "embedding_dim = len(embedding_model.embed_query(\"foo\"))\n",
        "\n",
        "def create_milvus_collection(collection_name: str):\n",
        "    if milvus_client.has_collection(collection_name=collection_name):\n",
        "        milvus_client.drop_collection(collection_name=collection_name)\n",
        "    milvus_client.create_collection(\n",
        "        collection_name=collection_name,\n",
        "        dimension=embedding_dim,\n",
        "        consistency_level=\"Strong\",\n",
        "    )\n",
        "\n",
        "\n",
        "entity_col_name = \"entity_collection\"\n",
        "relation_col_name = \"relation_collection\"\n",
        "passage_col_name = \"passage_collection\"\n",
        "create_milvus_collection(entity_col_name)\n",
        "create_milvus_collection(relation_col_name)\n",
        "create_milvus_collection(passage_col_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insert the data with their metadata information into Milvus collections, including entity, relation, and passage collections. The metadata information includes the passage id and the adjacency entity or relation id."
      ],
      "metadata": {
        "collapsed": false,
        "id": "ya9Is-tYWE-i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "NKmZ9YosWE-i",
        "outputId": "1e7fde91-6f7d-4b46-bc2d-106e5a81a164",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inserting: 100%|██████████| 1/1 [00:05<00:00,  5.59s/it]\n",
            "Inserting: 100%|██████████| 1/1 [00:06<00:00,  6.00s/it]\n",
            "Inserting: 100%|██████████| 1/1 [00:05<00:00,  5.59s/it]\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "def milvus_insert(\n",
        "    collection_name: str,\n",
        "    text_list: list[str],\n",
        "):\n",
        "    batch_size = 512\n",
        "    for row_id in tqdm(range(0, len(text_list), batch_size), desc=\"Inserting\"):\n",
        "        time.sleep(5)                                                                # added this to avoid rate limit reach error\n",
        "        batch_texts = text_list[row_id : row_id + batch_size]\n",
        "        batch_embeddings = embedding_model.embed_documents(batch_texts)\n",
        "\n",
        "        batch_ids = [row_id + j for j in range(len(batch_texts))]\n",
        "        batch_data = [\n",
        "            {\n",
        "                \"id\": id_,\n",
        "                \"text\": text,\n",
        "                \"vector\": vector,\n",
        "            }\n",
        "            for id_, text, vector in zip(batch_ids, batch_texts, batch_embeddings)\n",
        "        ]\n",
        "        milvus_client.insert(\n",
        "            collection_name=collection_name,\n",
        "            data=batch_data,\n",
        "        )\n",
        "\n",
        "\n",
        "milvus_insert(\n",
        "    collection_name=relation_col_name,\n",
        "    text_list=relations,\n",
        ")\n",
        "\n",
        "milvus_insert(\n",
        "    collection_name=entity_col_name,\n",
        "    text_list=entities,\n",
        ")\n",
        "\n",
        "milvus_insert(\n",
        "    collection_name=passage_col_name,\n",
        "    text_list=passages,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "online retrieval\n",
        "\n",
        "\n",
        "Similarity Retrieval\n",
        "\n",
        "\n",
        "We retrieve the topK similar entities and relations based on the input query from Milvus.\n",
        "\n",
        "When performing the entity retrieving, we should first extract the query entities from the query text using some specific method like NER (Named-entity recognition). For simplicity, we prepare the NER results here. If you want to change the query as your custom question, you have to change the corresponding query NER list.\n",
        "In practice, you can use any other model or approach to extract the entities from the query."
      ],
      "metadata": {
        "collapsed": false,
        "id": "FPkhTpgtWE-i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "exUDD-wIWE-i"
      },
      "outputs": [],
      "source": [
        "query = \"What contribution did the son of Euler's teacher make?\"\n",
        "\n",
        "query_ner_list = [\"Euler\"]\n",
        "# query_ner_list = ner(query) # In practice, replace it with your custom NER approach\n",
        "\n",
        "query_ner_embeddings = [\n",
        "    embedding_model.embed_query(query_ner) for query_ner in query_ner_list\n",
        "]\n",
        "\n",
        "top_k = 3\n",
        "\n",
        "entity_search_res = milvus_client.search(\n",
        "    collection_name=entity_col_name,\n",
        "    data=query_ner_embeddings,\n",
        "    limit=top_k,\n",
        "    output_fields=[\"id\"],\n",
        ")\n",
        "\n",
        "query_embedding = embedding_model.embed_query(query)\n",
        "\n",
        "relation_search_res = milvus_client.search(\n",
        "    collection_name=relation_col_name,\n",
        "    data=[query_embedding],\n",
        "    limit=top_k,\n",
        "    output_fields=[\"id\"],\n",
        ")[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we construct an adjacency matrix and use matrix multiplication to calculate the adjacency mapping information within a few degrees. In this way, we can quickly obtain information of any degree of expansion."
      ],
      "metadata": {
        "collapsed": false,
        "id": "XpUfHuCCWE-j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "-O6Rp6PoWE-j"
      },
      "outputs": [],
      "source": [
        "# Construct the adjacency matrix of entities and relations where the value of the adjacency matrix is 1 if an entity is related to a relation, otherwise 0.\n",
        "entity_relation_adj = np.zeros((len(entities), len(relations)))\n",
        "for entity_id, entity in enumerate(entities):\n",
        "    entity_relation_adj[entity_id, entityid_2_relationids[entity_id]] = 1\n",
        "\n",
        "# Convert the adjacency matrix to a sparse matrix for efficient computation.\n",
        "entity_relation_adj = csr_matrix(entity_relation_adj)\n",
        "\n",
        "# Use the entity-relation adjacency matrix to construct 1 degree entity-entity and relation-relation adjacency matrices.\n",
        "entity_adj_1_degree = entity_relation_adj @ entity_relation_adj.T\n",
        "relation_adj_1_degree = entity_relation_adj.T @ entity_relation_adj\n",
        "\n",
        "# Specify the target degree of the subgraph to be expanded.\n",
        "# 1 or 2 is enough for most cases.\n",
        "target_degree = 1\n",
        "\n",
        "# Compute the target degree adjacency matrices using matrix multiplication.\n",
        "entity_adj_target_degree = entity_adj_1_degree\n",
        "for _ in range(target_degree - 1):\n",
        "    entity_adj_target_degree = entity_adj_target_degree * entity_adj_1_degree\n",
        "relation_adj_target_degree = relation_adj_1_degree\n",
        "for _ in range(target_degree - 1):\n",
        "    relation_adj_target_degree = relation_adj_target_degree * relation_adj_1_degree\n",
        "\n",
        "entity_relation_adj_target_degree = entity_adj_target_degree @ entity_relation_adj"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By taking the value from the target degree expansion matrix, we can easily expand the corresponding degree from the retrieved entity and relations to obtain all relations of the subgraph."
      ],
      "metadata": {
        "collapsed": false,
        "id": "pTSi-v5pWE-j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "expanded_relations_from_relation = set()\n",
        "expanded_relations_from_entity = set()\n",
        "# You can set the similarity threshold here to guarantee the quality of the retrieved ones.\n",
        "# entity_sim_filter_thresh = ...\n",
        "# relation_sim_filter_thresh = ...\n",
        "\n",
        "filtered_hit_relation_ids = [\n",
        "    relation_res[\"entity\"][\"id\"]\n",
        "    for relation_res in relation_search_res\n",
        "    # if relation_res['distance'] > relation_sim_filter_thresh\n",
        "]\n",
        "for hit_relation_id in filtered_hit_relation_ids:\n",
        "    expanded_relations_from_relation.update(\n",
        "        relation_adj_target_degree[hit_relation_id].nonzero()[1].tolist()\n",
        "    )\n",
        "\n",
        "filtered_hit_entity_ids = [\n",
        "    one_entity_res[\"entity\"][\"id\"]\n",
        "    for one_entity_search_res in entity_search_res\n",
        "    for one_entity_res in one_entity_search_res\n",
        "    # if one_entity_res['distance'] > entity_sim_filter_thresh\n",
        "]\n",
        "\n",
        "for filtered_hit_entity_id in filtered_hit_entity_ids:\n",
        "    expanded_relations_from_entity.update(\n",
        "        entity_relation_adj_target_degree[filtered_hit_entity_id].nonzero()[1].tolist()\n",
        "    )\n",
        "\n",
        "# Merge the expanded relations from the relation and entity retrieval ways.\n",
        "relation_candidate_ids = list(\n",
        "    expanded_relations_from_relation | expanded_relations_from_entity\n",
        ")\n",
        "\n",
        "relation_candidate_texts = [\n",
        "    relations[relation_id] for relation_id in relation_candidate_ids\n",
        "]"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "U_OR82XlWE-k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have get the candidate relationships by expanding the subgraph, which will be reranked by LLM in the next step."
      ],
      "metadata": {
        "collapsed": false,
        "id": "uOWPL6h4WE-k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LLM reranking\n",
        "\n",
        "In this stage, we deploy the powerful self-attention mechanism of LLM to further filter and refine the candidate set of relationships. We employ a one-shot prompt, incorporating the query and the candidate set of relationships into the prompt, and instruct LLM to select potential relationships that could assist in answering the query. Given that some queries may be complex, we adopt the Chain-of-Thought approach, allowing LLM to articulate its thought process in its response. We stipulate that LLM's response is in json format for convenient parsing."
      ],
      "metadata": {
        "collapsed": false,
        "id": "G2GCqdABWE-k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "JfallAspWE-k"
      },
      "outputs": [],
      "source": [
        "query_prompt_one_shot_input = \"\"\"I will provide you with a list of relationship descriptions. Your task is to select 3 relationships that may be useful to answer the given question. Please return a JSON object containing your thought process and a list of the selected relationships in order of their relevance.\n",
        "\n",
        "Question:\n",
        "When was the mother of the leader of the Third Crusade born?\n",
        "\n",
        "Relationship descriptions:\n",
        "[1] Eleanor was born in 1122.\n",
        "[2] Eleanor married King Louis VII of France.\n",
        "[3] Eleanor was the Duchess of Aquitaine.\n",
        "[4] Eleanor participated in the Second Crusade.\n",
        "[5] Eleanor had eight children.\n",
        "[6] Eleanor was married to Henry II of England.\n",
        "[7] Eleanor was the mother of Richard the Lionheart.\n",
        "[8] Richard the Lionheart was the King of England.\n",
        "[9] Henry II was the father of Richard the Lionheart.\n",
        "[10] Henry II was the King of England.\n",
        "[11] Richard the Lionheart led the Third Crusade.\n",
        "\n",
        "\"\"\"\n",
        "query_prompt_one_shot_output = \"\"\"{\"thought_process\": \"To answer the question about the birth of the mother of the leader of the Third Crusade, I first need to identify who led the Third Crusade and then determine who his mother was. After identifying his mother, I can look for the relationship that mentions her birth.\", \"useful_relationships\": [\"[11] Richard the Lionheart led the Third Crusade\", \"[7] Eleanor was the mother of Richard the Lionheart\", \"[1] Eleanor was born in 1122\"]}\"\"\"\n",
        "\n",
        "query_prompt_template = \"\"\"Question:\n",
        "{question}\n",
        "\n",
        "Relationship descriptions:\n",
        "{relation_des_str}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def rerank_relations(\n",
        "    query: str, relation_candidate_texts: list[str], relation_candidate_ids: list[str]\n",
        ") -> list[int]:\n",
        "    relation_des_str = \"\\n\".join(\n",
        "        map(\n",
        "            lambda item: f\"[{item[0]}] {item[1]}\",\n",
        "            zip(relation_candidate_ids, relation_candidate_texts),\n",
        "        )\n",
        "    ).strip()\n",
        "    rerank_prompts = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            HumanMessage(query_prompt_one_shot_input),\n",
        "            AIMessage(query_prompt_one_shot_output),\n",
        "            HumanMessagePromptTemplate.from_template(query_prompt_template),\n",
        "        ]\n",
        "    )\n",
        "    rerank_chain = (\n",
        "        rerank_prompts\n",
        "        | llm.bind(response_format={\"type\": \"json_object\"})\n",
        "        | JsonOutputParser()\n",
        "    )\n",
        "    rerank_res = rerank_chain.invoke(\n",
        "        {\"question\": query, \"relation_des_str\": relation_des_str}\n",
        "    )\n",
        "    rerank_relation_ids = []\n",
        "    rerank_relation_lines = rerank_res[\"useful_relationships\"]\n",
        "    id_2_lines = {}\n",
        "    for line in rerank_relation_lines:\n",
        "        id_ = int(line[line.find(\"[\") + 1 : line.find(\"]\")])\n",
        "        id_2_lines[id_] = line.strip()\n",
        "        rerank_relation_ids.append(id_)\n",
        "    return rerank_relation_ids\n",
        "\n",
        "\n",
        "rerank_relation_ids = rerank_relations(\n",
        "    query,\n",
        "    relation_candidate_texts=relation_candidate_texts,\n",
        "    relation_candidate_ids=relation_candidate_ids,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Final Results\n",
        "\n",
        "We can get final retrieved passages from the reranked relationships."
      ],
      "metadata": {
        "collapsed": false,
        "id": "Yy1LSqTNWE-k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "clGlrQ30WE-l"
      },
      "outputs": [],
      "source": [
        "final_top_k = 2\n",
        "\n",
        "final_passages = []\n",
        "final_passage_ids = []\n",
        "for relation_id in rerank_relation_ids:\n",
        "    for passage_id in relationid_2_passageids[relation_id]:\n",
        "        if passage_id not in final_passage_ids:\n",
        "            final_passage_ids.append(passage_id)\n",
        "            final_passages.append(passages[passage_id])\n",
        "passages_from_our_method = final_passages[:final_top_k]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We can compare the results with the naive RAG method, which retrieves the topK passages based on the query embedding directly from the passage collection."
      ],
      "metadata": {
        "collapsed": false,
        "id": "k87WifOFWE-l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "AWchJZk7WE-l",
        "outputId": "80752be5-6661-4864-8758-f26548e81684",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passages retrieved from naive RAG: \n",
            "['Leonhard Euler (1707–1783) was one of the greatest mathematicians of all time, and his relationship with the Bernoulli family was significant. Euler was born in Basel and was a student of Johann Bernoulli, who recognized his exceptional talent and mentored him in mathematics. Johann Bernoulli’s influence on Euler was profound, and Euler later expanded upon many of the ideas and methods he learned from the Bernoullis.', 'Daniel Bernoulli (1700–1782): The son of Johann Bernoulli, Daniel made major contributions to fluid dynamics, probability, and statistics. He is most famous for Bernoulli’s principle, which describes the behavior of fluid flow and is fundamental to the understanding of aerodynamics.']\n",
            "\n",
            "Passages retrieved from our method: \n",
            "['Leonhard Euler (1707–1783) was one of the greatest mathematicians of all time, and his relationship with the Bernoulli family was significant. Euler was born in Basel and was a student of Johann Bernoulli, who recognized his exceptional talent and mentored him in mathematics. Johann Bernoulli’s influence on Euler was profound, and Euler later expanded upon many of the ideas and methods he learned from the Bernoullis.', 'Daniel Bernoulli (1700–1782): The son of Johann Bernoulli, Daniel made major contributions to fluid dynamics, probability, and statistics. He is most famous for Bernoulli’s principle, which describes the behavior of fluid flow and is fundamental to the understanding of aerodynamics.']\n",
            "\n",
            "\n",
            "Answer from naive RAG: Daniel Bernoulli, the son of Euler's teacher Johann Bernoulli, made significant contributions to the fields of fluid dynamics, probability, and statistics. He is particularly known for Bernoulli's principle, which explains the behavior of fluid flow and is crucial in understanding aerodynamics. While Euler was influenced by the Bernoulli family and built upon their work, Daniel Bernoulli's contributions were distinct and substantial in their own right.\n",
            "\n",
            "Answer from our method: Daniel Bernoulli, the son of Euler's teacher Johann Bernoulli, made significant contributions to the fields of fluid dynamics, probability, and statistics. He is particularly known for Bernoulli's principle, which describes the behavior of fluid flow and is fundamental to the understanding of aerodynamics. While Euler was influenced by the Bernoullis and built upon their work, Daniel Bernoulli's contributions are distinct and notable in their own right.\n"
          ]
        }
      ],
      "source": [
        "naive_passage_res = milvus_client.search(\n",
        "    collection_name=passage_col_name,\n",
        "    data=[query_embedding],\n",
        "    limit=final_top_k,\n",
        "    output_fields=[\"text\"],\n",
        ")[0]\n",
        "passages_from_naive_rag = [res[\"entity\"][\"text\"] for res in naive_passage_res]\n",
        "\n",
        "print(\n",
        "    f\"Passages retrieved from naive RAG: \\n{passages_from_naive_rag}\\n\\n\"\n",
        "    f\"Passages retrieved from our method: \\n{passages_from_our_method}\\n\\n\"\n",
        ")\n",
        "\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"human\",\n",
        "            \"\"\"Use the following pieces of retrieved context to answer the question. If there is not enough information in the retrieved context to answer the question, just say that you don't know.\n",
        "Question: {question}\n",
        "Context: {context}\n",
        "Answer:\"\"\",\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "rag_chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "answer_from_naive_rag = rag_chain.invoke(\n",
        "    {\"question\": query, \"context\": \"\\n\".join(passages_from_naive_rag)}\n",
        ")\n",
        "answer_from_our_method = rag_chain.invoke(\n",
        "    {\"question\": query, \"context\": \"\\n\".join(passages_from_our_method)}\n",
        ")\n",
        "\n",
        "print(\n",
        "    f\"Answer from naive RAG: {answer_from_naive_rag}\\n\\nAnswer from our method: {answer_from_our_method}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the retrieved passages from the naive RAG missed a ground-truth passage, which led to a wrong answer.\n",
        "The retrieved passages from our method are correct, and it helps to get an accurate answer to the question."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "8J4Zinx5WE-l"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "fyUVCmk5eFsg"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}